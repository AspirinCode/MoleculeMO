{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rdkit as rd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines if SMILES is valid or not\n",
    "def is_valid(smiles):\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    #Returns True if SMILES is valid, returns False if SMILES is invalid\n",
    "    return smiles != '' and mol is not None and mol.GetNumAtoms() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determines LogP\n",
    "def logP(smiles):\n",
    "    \n",
    "    return(Descriptors.MolLogP(Chem.MolFromSmiles(smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determins molecular weight\n",
    "def molWt(smiles):\n",
    "    \n",
    "    return(Descriptors.MolWt(Chem.MolFromSmiles(smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine number hydrogen bond acceptors\n",
    "def numAcc(smiles):\n",
    "    \n",
    "    return(Descriptors.NumHAcceptors(Chem.MolFromSmiles(smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine number hydrogen bond donors\n",
    "def numDon(smiles):\n",
    "    \n",
    "    return(Descriptors.NumHDonors(Chem.MolFromSmiles(smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine polar surface area\n",
    "def polSur(smiles):\n",
    "    \n",
    "    return(Descriptors.TPSA(Chem.MolFromSmiles(smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine number of rotatable bonds\n",
    "def rolBon(smiles):\n",
    "    return(Descriptors.NumRotatableBonds(Chem.MolFromSmiles(smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of characters generated\n",
    "num_characters = 0\n",
    "\n",
    "#Number of molecules generated\n",
    "num_smiles = 0\n",
    "\n",
    "#Number of unique SMILES\n",
    "num_unq_mols = 0\n",
    "\n",
    "#Number of unique SMILES that aren't in the training data\n",
    "num_mols = 0\n",
    "\n",
    "#Number of valid molecules that aren't in the training data generated\n",
    "num_valid = 0\n",
    "\n",
    "#List of smiles in file, to make sure smiles are unique\n",
    "smileslist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent valid molecules: 25.10394502698961\n"
     ]
    }
   ],
   "source": [
    "#Test how many molecules are valid (without considering uniqueness, novelty)\n",
    "total = 0\n",
    "number_valid = 0\n",
    "\n",
    "#Read in data file line by line\n",
    "for line in open(\"generatedsmiles.txt\", \"r\"):\n",
    "    total += 1\n",
    "    \n",
    "    #Ensure smiles are valid\n",
    "    if(is_valid(line) == True):\n",
    "                           \n",
    "        #Increment number of valid molecules generated\n",
    "        number_valid += 1\n",
    "\n",
    "print(\"Percent valid molecules: \" + str(number_valid / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training data\n",
    "training_data = list(open(\"smiles.txt\", \"r\"))\n",
    "\n",
    "#File with unique generated SMILES that aren't in the training data\n",
    "generatedmols = open(\"generatedmols.txt\", \"w\")\n",
    "\n",
    "#Read in data file line by line\n",
    "for line in open(\"generatedsmiles.txt\", \"r\"):\n",
    "    \n",
    "    #Ensure molecules are unique\n",
    "    if line not in smileslist:\n",
    "        \n",
    "        smileslist.append(line)\n",
    "        \n",
    "        num_unq_mols += 1\n",
    "\n",
    "        #Ensure smiles aren't in training data\n",
    "        if line not in training_data:  \n",
    "\n",
    "            #Remove \\n character, remove G character\n",
    "            smiles = line.replace(\"\\n\", \"\").replace(\"G\", \"\")\n",
    "            \n",
    "            #Increment number of molecules generated\n",
    "            num_mols += 1\n",
    "\n",
    "            #Ensure smiles are valid\n",
    "            if(is_valid(smiles) == True):\n",
    "            \n",
    "                #Copy over SMILES satisfying requirements\n",
    "                generatedmols.write(smiles + \"\\n\")\n",
    "                \n",
    "                #Increment number of valid molecules generated\n",
    "                num_valid += 1\n",
    "                \n",
    "    #Increment total number of SMILES generated\n",
    "    num_smiles += 1\n",
    "    \n",
    "    #Add length of line to total number of characters\n",
    "    num_characters += len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters generated: 9791155\n",
      "Number of molecules generated: 235461\n",
      "Number of unique molecules generated: 178821\n",
      "Number of novel and unique molecules generated: 178821\n",
      "Number of novel, unique, and valid molecules generated: 13308\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of characters generated: \" + str(num_characters))\n",
    "print(\"Number of molecules generated: \" + str(num_smiles))\n",
    "print(\"Number of unique molecules generated: \" + str(num_unq_mols))\n",
    "print(\"Number of novel and unique molecules generated: \" + str(num_mols))\n",
    "print(\"Number of novel, unique, and valid molecules generated: \" + str(num_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Morgan fingerprints of molecules\n",
    "fingerprints = []\n",
    "\n",
    "#Read in data file line by line\n",
    "for line in open(\"generatedmols.txt\", \"r\"):\n",
    "    \n",
    "    #Convert SMILES string to Morgan fingerprint\n",
    "    mol = Chem.MolFromSmiles(line.replace(\"\\n\", \"\"))\n",
    "    fingerprint = AllChem.GetMorganFingerprint(mol, 2)\n",
    "    \n",
    "    #Add to list of fingerprints\n",
    "    fingerprints.append(fingerprint)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Internal Diversity: 0.1256\n"
     ]
    }
   ],
   "source": [
    "#Total Tanimoto Distance\n",
    "tanimoto = 0\n",
    "\n",
    "#Calculate Tanimoto Distance between each pair of fingerprints\n",
    "for fpt1 in fingerprints:\n",
    "    for fpt2 in fingerprints:\n",
    "        \n",
    "        if fpt1 != fpt2:\n",
    "            \n",
    "            #Calculate Tanimoto Distance\n",
    "            tan = TanimotoSimilarity(fpt1, fpt2)\n",
    "            tanimoto += tan\n",
    "\n",
    "#Average Tanimoto Distance (internal diversity)\n",
    "avg_tanimoto = (1 / (num_valid ** 2)) * tanimoto\n",
    "print(\"Average Internal Diversity: {:0.4f}\".format(avg_tanimoto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of molecular properties for generated molecules\n",
    "molProps = np.empty((0,5))\n",
    "\n",
    "#Read in data file line by line\n",
    "for molecule in open(\"generatedmols.txt\", \"r\"):\n",
    "    try:\n",
    "        #Array of properties [partition coefficient, molecular weight, number of hydrogen bond acceptors, number of hydrogen bond donors, polar surface area]\n",
    "        props = np.reshape(np.array([logP(molecule), molWt(molecule), numAcc(molecule), numDon(molecule), rolBon(molecule)]), (1, 5))\n",
    "    \n",
    "        #Append properties\n",
    "        molProps = np.append(molProps, props, axis=0)\n",
    "        \n",
    "    except:\n",
    "        #Occasionally RDKit bugs don't allow for analyzing the molecule; in these cases, simply remove the molecule\n",
    "        molecule.replace(molecule, \"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of number of molecules each molecule is dominated by\n",
    "dom = np.zeros((np.shape(molProps)[0]))\n",
    "\n",
    "#Analyze each molecule's properties as they compare to others\n",
    "for i in range(np.shape(molProps)[0]):\n",
    "    \n",
    "    for j in range(np.shape(molProps)[0]):\n",
    "        \n",
    "        #Compare each property between the molecules\n",
    "        if (molProps[j, 0] <= molProps[i, 0]):\n",
    "            \n",
    "            if (molProps[j, 1] <= molProps[i, 1]):\n",
    "            \n",
    "                if (molProps[j, 2] <= molProps[i, 2]):\n",
    "\n",
    "                    if (molProps[j, 3] <= molProps[i, 3]):\n",
    "            \n",
    "                        if (molProps[j, 4] <= molProps[i, 4]):\n",
    "                            \n",
    "                            #If molecule j is better than molecule i in every property, than j dominates i\n",
    "                            dom[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many frontiers there are and how many molecules are in each frontier\n",
    "unique, counts = np.unique(dom, return_counts=True)\n",
    "fronts = dict(zip(unique, counts))\n",
    "\n",
    "#Indices of best molecules for use in finetuning\n",
    "fineMols = np.empty((0,1))\n",
    "\n",
    "#Fraction of molecules to be used for transfer learning\n",
    "top = 0.5\n",
    "\n",
    "#Frontier iterator \n",
    "f = 0\n",
    "#Get indices of the best (top) fraction of molecules\n",
    "while(np.shape(fineMols)[0] < (top * np.shape(molProps)[0])):\n",
    "\n",
    "    #Indices of molecules in frontier i\n",
    "    fineMolecules = np.transpose(np.where(dom == f))\n",
    "    \n",
    "    #Add to finemols\n",
    "    fineMols = np.append(fineMols, fineMolecules, axis=0)\n",
    "      \n",
    "    #Look at next worst frontier\n",
    "    f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save best molecules to transferdata.txt\n",
    "transferdata = open(\"transferdata.txt\", \"w\")\n",
    "\n",
    "#Index counter\n",
    "i = 0\n",
    "\n",
    "#Get best molecules and save them to transferdata.txt\n",
    "for line in open(\"generatedmols.txt\", \"r\"):\n",
    "    \n",
    "    #Get best molecules, write to new file\n",
    "    if i in fineMols:\n",
    "        \n",
    "        #Append start token\n",
    "        line = line.rjust(len(line)+1, \"G\")\n",
    "        \n",
    "        #Write to file\n",
    "        transferdata.write(line)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "#Close file\n",
    "transferdata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array of molecular properties for generated molecules\n",
    "transferMolProps = np.empty((0,5))\n",
    "\n",
    "#Read in data file line by line\n",
    "for molecule in open(\"transferdata.txt\", \"r\"):\n",
    "    \n",
    "    #Remove start token to analyze molecules\n",
    "    molecule = molecule.replace(\"G\", \"\")\n",
    "    \n",
    "    #Array of properties [partition coefficient, molecular weight, number of hydrogen bond acceptors, number of hydrogen bond donors, polar surface area]\n",
    "    transferProp = np.reshape(np.array([logP(molecule), molWt(molecule), numAcc(molecule), numDon(molecule), rolBon(molecule)]), (1, 5))\n",
    "    \n",
    "    #Append properties\n",
    "    transferMolProps = np.append(transferMolProps, transferProp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in original training data file to get character list\n",
    "data = open(\"smiles.txt\", \"r\").read()\n",
    "\n",
    "#Create a list of the unique characters in the dataset\n",
    "chars = list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Create array from characters in the dataset\n",
    "values = array(chars)\n",
    "valueslist = values.tolist()\n",
    "print(\"Array of unique characters:\")\n",
    "print(values)\n",
    "\n",
    "#Create unique, numerical labels for each character between 0 and n-1, where n is the number of unique characters\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Array of labels for each character:\")\n",
    "print(integer_encoded)\n",
    "\n",
    "#Encode characters into a one-hot encoding, resulting in an array of size [num unique chars, num unique chars]\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(\"Array of one-hot encoded characters:\")\n",
    "print(onehot_encoded)\n",
    "print(\"Size of array of one-hot encoded characters: \" + str(onehot_encoded.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in transfer data file\n",
    "data = open(\"transferdata.txt\", \"r\").read()\n",
    "#Create a list of the dataset, along with all the characters to ensure they are all represeented\n",
    "datalist = list(data)\n",
    "datalist.extend(valueslist)\n",
    "#Create an array of the dataset\n",
    "dataarray = array(datalist)\n",
    "#Fit one-hot encoding to dataarray\n",
    "dataarray = dataarray.reshape(len(dataarray), 1)\n",
    "#Fit encoder, remove all characters at the end leaving just the molecules\n",
    "ohefinemols = onehot_encoder.fit_transform(dataarray).astype(int)[0:31980,:]\n",
    "print(\"Size of one-hot encoded array of data: \" + str(ohefinemols.shape))\n",
    "print(\"One-hot encoded array of data:\")\n",
    "print(ohefinemols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save ohefinemols as a (compressed) file\n",
    "np.savez_compressed(\"ohefinemols.npz\", ohefinemols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create integer transfer data\n",
    "intfinemols = [np.where(r==1)[0][0] for r in ohefinemols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save intfinemols as a (compressed) file\n",
    "np.savez_compressed(\"intfinemols.npz\", intfinemols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array with SMILES character, integer encoding, and one hot encoding (vocabulary)\n",
    "values = np.reshape(values, (np.shape(values)[0], 1))\n",
    "vocab = np.concatenate((values, integer_encoded.astype(object)), axis = 1)\n",
    "vocab = vocab[vocab[:,1].argsort()]\n",
    "vocabvalues = np.reshape(vocab[:,1], (-1,1))\n",
    "vocabohe = onehot_encoder.fit_transform(vocabvalues)\n",
    "vocabencodings = np.concatenate((vocab, vocabohe.astype(object)), axis = 1)\n",
    "print(np.shape(vocabencodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocabencodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA visualization\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Scale array of properties for all molecules\n",
    "scaledProps = StandardScaler().fit_transform(np.concatenate((molProps, transferMolProps), axis=0))\n",
    "\n",
    "#Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(scaledProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(principalComponents[0:np.shape(molProps)[0],0],principalComponents[0:np.shape(molProps)[0],1], 75)\n",
    "plt.scatter(principalComponents[np.shape(molProps)[0]:,0],principalComponents[np.shape(molProps)[0]:,1], 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
